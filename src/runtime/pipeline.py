import os
import ctypes
import sys
import string
import numpy as np
import ConfigParser
import desglue
import time

from . import utils
from . import inifiles
from . import termcolor
from . import options
from . import data_package
from . import section_names
from . import priors

MODULE_TYPE_EXECUTE_SIMPLE = "execute"
MODULE_TYPE_EXECUTE_CONFIG = "execute_config"
MODULE_TYPE_SETUP   = "setup"
MODULE_TYPE_CLEANUP = "cleanup"

class SetupError(Exception):
	pass


def load_interface(library_path, function_name, module_type=MODULE_TYPE_EXECUTE_SIMPLE):
	"Load a module from a shared library"
	dll=ctypes.cdll.LoadLibrary(library_path)
	try:
		function=getattr(dll,function_name)
	except AttributeError:
		function = getattr(dll,function_name + "_")
	if module_type==MODULE_TYPE_EXECUTE_SIMPLE:
		function.argtypes = [ctypes.c_voidp]
		function.restype = ctypes.c_int
	elif module_type==MODULE_TYPE_EXECUTE_CONFIG:
		function.argtypes = [ctypes.c_voidp, ctypes.c_voidp]
		function.restype = ctypes.c_int
	elif module_type==MODULE_TYPE_SETUP:
		function.argtypes = [ctypes.c_voidp]
		function.restype = ctypes.c_voidp
	elif module_type==MODULE_TYPE_CLEANUP:
		function.argtypes = [ctypes.c_voidp]
		function.restype = ctypes.c_int
	else:
		raise ValueError("Unknown module type passed to load_interface")
	return function


def load_module(filepath, function_name, module_type=MODULE_TYPE_EXECUTE_SIMPLE):
	"Load a module either from a python file or a shared library"
	if filepath.endswith('so') or filepath.endswith('dylib'):
		#parse as module
		try:
			return load_interface(filepath, function_name, module_type)
		except OSError as error:
			exists = os.path.exists(filepath)
			if exists:
				raise SetupError("You specified a path %s for a module. File exists, but could not open. Error was %s" % (filepath,error))
			else:
				raise SetupError("You specified a path %s for a module. File does not exist.  Error was %s" % (filepath,error))
		except AttributeError:
			raise SetupError("You asked in the ini file to find a function %s in the file %s.  I could not find it." %(function_name, filepath))
	else:
		dirname, filename = os.path.split(filepath)
		import sys
		sys.path.insert(0,dirname)
		impname = filename
		if impname.endswith(".py"):
			impname = impname[:-len(".py")]
		try:
			module = __import__(impname)
		except ImportError as error:
			message = """I looked for a python module called %s in the directory 
called %s, but was unable to load it.  Either it was not there or there was some 
problem with it:
 - You might need to change the "root" setting in your param file
 - Or the path to this module as specified by "file=" in that same ini file.
 - Or it might depend on some other module I could not find. 
The full message was: %s""" % (filename, dirname, error.message)
			raise SetupError(message)
		#remove the item we just added to the path.  This means we can call this function many times on the same file if we want.
		sys.path[0:1] = []
		return getattr(module,function_name)




class Pipeline(object):
	def __init__(self, arg=None, quiet=False, debug=False, timing=False):
		"""Initialize with a single filename or a list of them, a ConfigParser, or nothing for an empty pipeline"""
		if arg is None: arg = list()
		if isinstance(arg, ConfigParser.ConfigParser):
			self.options = arg
		else:
			self.options = inifiles.Inifile.from_file(arg)
		if "pipeline" in self.options.sections():
			self.root = self.get_option("pipeline","root",".")
			self.module_names = self.get_option("pipeline","modules","").split()
		else:
			self.root = "."
			self.module_names = []
		
		self.paths = []
		self.functions = []
		self.modules = []
		self.module_data = []
		self.load_modules()
		self.quiet=quiet
		self.debug=debug
		self.timing=timing

	def load_modules(self):
		for module_name in self.module_names:
			# Find the filename  for the module.
			# Generate the complete path to it.
			filename = self.get_option(module_name, "file")
			if filename.startswith('/'):
				path = filename
				print "Because it starts with a '/' I used an absolute path for: ", path
			else:
				path = os.path.join(self.root, filename)
			self.paths.append(path)

			#Get the module execution function name, assumed to be "execute"
			#if not otherwise specified
			function = self.get_option(module_name, "function", "execute")
			self.functions.append(function)

			# Look for and run a setup function if one is specified.
			# and record configuration data returned from it.
			setup_data = self.setup_module(module_name, path)
			self.module_data.append(setup_data)
			#If a setup function was found then configuration data 
			#generated by it will be passed to the execution function.
			#so we need to both record this data (as above)
			#and load the correct module signature to go with this
			if setup_data is None:
				module_type = MODULE_TYPE_EXECUTE_SIMPLE
			else:
				module_type = MODULE_TYPE_EXECUTE_CONFIG

			#We now have set up the module data and know its type
			#so we can load the module itself and record it
			module = load_module(path, function, module_type)
			self.modules.append(module)

	def setup_module(self, module_name, path):
		#Look for a setup function specified in the parameter file.
		#if none is found then there is no setup to do.
		setup_name = self.get_option(module_name, "setup", "")
		if not setup_name: 
			return None

		#Otherwise, find all the options relevant to this module, and pass them in.
		#Might have to change this behaviour if it turns out to be to restrictive for people
		#The rationale is that in this form you can re-run the same module multiple times
		#with different configuration data.
		#
		# Runtime is not really an issue here since this bit will only be run once
		# per process.
		#
		#For example, you could create a module that computes likelihoods in the same way on several 
		#different data sets
		relevant_sections = ["pipeline", "general", "logging", "debug", module_name]
		relevant_options = []
		for (section, param, value) in self.options.iter_all():
			if section not in relevant_sections: 
				continue
			if section==module_name:
				relevant_options.append((options.DesOptionPackage._default_section, param, value))
			relevant_options.append((section, param, value))
		relevant_options.append((options.DesOptionPackage._default_section, "module_name", module_name))
		#Once we have the options convert them into a (C/C++/Fortran-readable) optionset object
		options_handle = desglue.create_options(relevant_options)
		# We load the setup function that will accept this object.
		# and finally return the result of the setup function.
		# It is probably OK for the setup function to bug out and quit - that would
		# seem to be the most straightforward way of handling an error there (???)
		try:
			setup_function = load_module(path, setup_name, MODULE_TYPE_SETUP)
		except AttributeError:
			message = "You specified a setup function called %s for the module %s, but I could not find it in %s" % (setup_name, module_name, path)
			raise SetupError(message)

		return setup_function(options_handle)


	def get_option(self,section,name,default=None):
		try:
			return self.options.get(section,name)
		except ConfigParser.NoOptionError:
			if default is not None:
				return default
			raise ValueError("Could not find entry in the ini file for section %s, parameter %s, which was needed." % (section,name))
	
	def get_boolean(self, section, name, default=None):
		text = self.get_option(section, name, default)
		return utils.boolean_string(text)

	def get_pipeline_option(self, name):
		return self.options.get("pipeline",name)

	def run(self, package):
		"""Pass in either a DesDataPackage or a handle to a data block.  You will get out what you put in."""
		if isinstance(package, data_package.DesDataPackage):
			handle = package.to_new_fits_handle()
			own_handle = True
		else:
			handle = int(package)
			own_handle = False
		if self.timing:
			timings = [time.clock()]
		#Loop through the modules and the configuration data.
		for (module_name, module, module_data) in zip(self.module_names, self.modules, self.module_data):
			#If module_data is None that is a code indicating that the
			#module does not require/accept any configuration data and
			#so should accept just the one (data package) argument.
			if self.debug:
				sys.stdout.write("Running %.20s ... " % module_name)
				sys.stdout.flush()
			if module_data is None:
				status = module(handle)
			#Otherwise we pass in both
			else:
				status = module(handle, module_data)
			if self.timing:
				timings.append(time.clock())
			if status:
				if not self.quiet:
					message = termcolor.colored("Error running pipeline (%d)- hopefully printed above here.\n"%status, 'white',on_color='on_red')
					sys.stderr.write(message)
					sys.stderr.write("Aborting this run and returning error status.\n")
					if self.timing:
						sys.stdout.write("Module timing:\n")
						for name,t2,t1 in zip(self.module_names[:], timings[1:], timings[:-1]):
							sys.stdout.write("%s %f\n"%(name, t2-t1))
				return None
			if self.debug:
				sys.stdout.write("%d\n" % status)
				sys.stdout.flush()

		if not self.quiet:
			message = termcolor.colored("Pipeline ran okay.", 'green', attrs=['bold'])
			print message
		if self.timing:
			sys.stdout.write("Module timing:\n")
			for name, t2,t1 in zip(self.module_names, timings[1:], timings[:-1]):
				sys.stdout.write("%s %f\n"%(name, t2-t1))
		if own_handle:
			package = data_package.DesDataPackage.from_fits_handle(handle)
			desglue.free_fits(handle)
			return package
		else:
			return handle




class Covmat(object):
	def __init__(self, cov, names=None):
		""" Generate a covariance matrix."""
		self.cov = cov
		self.n = len(cov)
		if names is None:
			self.names = ['P_%d'%i for i in xrange(1,self.n+1)]
		else:
			self.names=names
			if len(self.names)!=self.n:
				raise ValueError("Covariance matrix had different dimension (%d) to number of names (%d)" % (self.n, len(self.names)))

	@classmethod
	def from_file(cls, filename, param_names=None):
		cov = np.loadtxt(filename)
		if param_names is None:
			line = open(filename).readline().strip()
			if line.startswith('#'):
				maybe_names = line[1:].split()
				if len(maybe_names)==len(cov):
					param_names = maybe_names
		return cls(cov, param_names)

	def to_file(self, filename):
		f = open(filename,'w')
		f.write('# ')
		f.write(' '.join(self.names))
		f.write('\n')
		np.savetxt(f, self.cov, fmt='%.8e')

	def pretty_print(self):
		print ' '*10,
		for name in self.names:
			print '%10s'%name,
		print
		for cov_line,name in zip(self.cov, self.names):
			print '%10s'%name, 
			print ' '.join(['% .10e '%x for x in cov_line])



PIPELINE_INI_SECTION = "pipeline"


class LikelihoodPipeline(Pipeline):
	def __init__(self, arg=None, id="", debug=False, quiet=False, timing=False):
		super(LikelihoodPipeline, self).__init__(arg=arg, quiet=quiet, debug=debug, timing=timing)
		param_values_filename = self.get_option(PIPELINE_INI_SECTION,"values")
		self.quiet = utils.boolean_string(self.get_option(PIPELINE_INI_SECTION,"quiet","False"))
		priors_files = self.get_option(PIPELINE_INI_SECTION, "priors", "")
		self.priors_calculator = priors.PriorCalculator(priors_files.split())

# 		try:
# 			self.blind = self.get_boolean(PIPELINE_INI_SECTION,"blind",".")
# 		except (KeyError, ValueError):
# 			sys.stderr.write("""
# Aborting:
# Blind analyses are now enabled with this code; we can hide the true value of parameters
# from users to avoid experimenter bias.  You can switch this on or off.

# You now need to specify blind=T or blind=F in the [pipeline] section of your parameter ini file.
# Either that parameter was not set or it was set to something funny.

# """)
# 			sys.exit(1)

		if id:
			self.id_code = "[%s] " % str(id)
		else:
			self.id_code = ""
		self.n_iterations = 0

		#We want to save some parameter results from the run for further output
		extra_saves = self.get_option(PIPELINE_INI_SECTION,"extra_output", "")
		self.extra_saves = []
		for extra_save in extra_saves.split():
			section, name = extra_save.split('/')
			section = section.upper()
			name = name.upper()
			section = getattr(section_names.section_names, section.lower(), section)
			self.extra_saves.append((section, name))


		#Load the values file and get all the parameters from it.
		param_value_file = inifiles.ParameterRangesFile.from_file(param_values_filename)
		param_info = param_value_file.param_list()

		#Now split these into varied (sampled) parameters and fixed ones
		self.varied_params = []
		self.fixed_params = []
		#Loop throuh the parameters and get their ranges.
		#a range where min==max indicates a fixed parameter.
		# min<max indicates varied
		# and anything else is an error
		for (section, param, param_range) in param_info:
			param_min, param_start, param_max = param_range
			#Check for some obvious errors
			if param_min>param_max:
				raise ValueError("In your values file you set min>max for parameter %s in section %s (%r>%r). This can also be a symptom of a typo in the parameter line." % (param,section,param_min, param_max) )
			elif param_start>param_max or param_start<param_min:
				raise ValueError("In your values file you set a starting value (%r) for parameter %s in section %s outside the min-max range (%r to %r). This can also be a symptom of a typo in the parameter line." % (param_start, param,section,param_min, param_max) )
			elif param_min==param_max: 
				#parameter is fixed - no problem.
				self.fixed_params.append((section, param, param_start))
			else:
				#parameter is varied
				self.varied_params.append((section, param, param_range))

		#pull out all the section names and likelihood names for later
		self.section_names = set([name for (name, param, value) in self.fixed_params+self.varied_params])
		self.likelihood_names = self.get_option("pipeline","likelihoods").split()

	def randomized_start(self):
		output = np.zeros(len(self.varied_params))
		for i,(section, name, param_range) in enumerate(self.varied_params):
			(pmin, pstart, pmax) = param_range
			output[i] = pstart + (pmax-pmin)/100.0 * np.random.randn()
		return output

	def is_out_of_range(self, params_by_section):
		out_of_range = []
		for (section, param, param_range) in self.varied_params:
			value = params_by_section[section][param]
			(pmin, pstart, pmax) = param_range
			if value<pmin:
				out_of_range.append("%s--%s=%.4g<%.4g"%(section,param,value,pmin))
			elif value>pmax:
				out_of_range.append("%s--%s=%.4g>%.4g"%(section,param,value,pmax))
		if out_of_range:
			if not self.quiet:
				print "Params out of range: " +  ('  '.join(out_of_range))
				print "Zero likelihood"
			return True
		return False			


	def set_run_parameters(self, p):
		#Set up the sections of parameters
		params_by_section = {}
		for section_name in self.section_names:
			params_by_section[section_name] = {}

		#Loop through the fixed parameters setting their values
		help_notes = []
		for (section, param, param_start) in self.fixed_params:
			params_by_section[section][param] = param_start

		#Now loop the varied ones.
		for (section, param, param_range), value in zip(self.varied_params, p):
			params_by_section[section][param] = value
			if not self.quiet: help_notes.append("%s--%s=%e" % (section,param,value))

		#Check for parameters being above the min/max values they are allowed.
		if self.is_out_of_range(params_by_section):
			return None
		
		if not self.quiet:
			help_text = '  '.join(help_notes)
			print "%sRunning pipeline iteration %d: %s" % (self.id_code, self.n_iterations, help_text)
		return params_by_section

	def write_values_file(self, p, output_file):
		""" Turn a parameter vector into a values file """
		quiet = self.quiet
		self.quiet=False
		params_by_section = self.set_run_parameters(p)
		self.quiet=quiet
		if params_by_section is None:
			print "Bad parameters:"
			print p
			return	
		if isinstance(output_file,file):
			f = output_file
		else:
			f = open(output_file, 'w')
		for section_name, section_dict in params_by_section.items():
			section_name = utils.section_friendly_names[section_name]
			f.write('[%s]\n'%section_name)
			for name, value in section_dict.items():
				f.write("%-18s = %s\n" % (name,str(value)))
			f.write("\n")
		if not isinstance(output_file,file):
			f.close()

	@staticmethod
	def data_package_from_start(start=None):
		if isinstance(start, data_package.DesDataPackage):
			data = start
		elif isinstance(start, basestring):
			data = data_package.DesDataPackage.from_file(start)
		elif start is None:
			data = data_package.DesDataPackage()
		else:
			raise ValueError("Could not convert object %r into a data package (internal error; report this please)"%start)
		return data

	def run_vector(self,p,start=None):
		params_by_section = self.set_run_parameters(p)
		if params_by_section is None:
			return None
		return self.run_parameters(params_by_section, start=start)

	def starting_vector(self):
		return np.array([r[2][1] for r in self.varied_params])

	def run_parameters(self, params_by_section, start=None, check_ranges=False):
		if params_by_section is None:
			return None
		if check_ranges:
			if self.is_out_of_range(params_by_section):
				return None
		data = self.data_package_from_start(start)
		data.add_mixed_params(params_by_section)
		data = self.run(data)
		return data

	def run_ranges_file(self, ranges_file, start=None):
		params_by_section = ranges_file.to_fixed_parameter_dicts()
		return self.run_parameters(params_by_section, start=start)

	def extract_likelihood(self, data):
		like = 0.0
		like_section = section_names.section_names.likelihoods
		for likelihood_name in self.likelihood_names:
			like += data.get_param(like_section,likelihood_name+"_LIKE")
		return like

	def header_text(self):
		param_names = ["%s--%s"%(p[0],p[1]) for p in self.varied_params]
		output = ['# Likelihood   ']
		output+=["%-20s"%p for p in param_names]
		output+= ['%s--%s'%param for param in self.extra_saves]
		return '\t'.join(output)

	def parameter_output_text(self, like, params, extra_data):
		output = ["%-20s"%str(like)]
		for (section,name,_) in self.varied_params:
			value = params[section][name]
			output.append("%-20s"%str(value))
		for (section,name,_) in self.extra_saves:
			value = extra_data[section][name]
			output.append("%-20s"%str(value))
		return '\t'.join(output)

	def denormalize_vector(self, p):
		p_out = []
		for (section, param, param_range), value in zip(self.varied_params, p):
			param_min, param_start, param_max = param_range
			p_i = value*(param_max-param_min) + param_min
			p_out.append(p_i)
		return np.array(p_out)

	def normalize_vector(self, p):
		p_out = []
		for (section, param, param_range), value in zip(self.varied_params, p):
			param_min, param_start, param_max = param_range
			p_i = (value - param_min)/(param_max - param_min)
			p_out.append(p_i)
		return np.array(p_out)

	@staticmethod
	def nested_dict_to_single_dict(D):
		output = {}
		for section, d in D.items():
			for name,value in d.items():
				output[(section,name)] = value
		return output

	def prior(self, p):
		if not self.priors_calculator:
			return 0.0
		if isinstance(p, dict):
			return self.priors_calculator.get_prior_for_nested_dict(p)
		else:			
			param_dict = {}
			for (section, param, param_range), value in zip(self.varied_params, p):
				param_dict[(section,param)] = value
			return self.priors_calculator.get_prior_for_collected_parameter_dict(param_dict)

	def posterior(self, p, filename=None):
		prior = self.prior(p)
		if prior == -np.inf:
			return prior, utils.everythingIsNan
		like, extra = self.likelihood(p, filename=filename)
		return prior + like, extra

	def likelihood(self, p, filename=None):
		self.n_iterations += 1
		#Set the parameters by name from the parameter vector
		#If one is out of range then return -infinity as the log-likelihood
		#i.e. likelihood is zero.  Or if something else goes wrong do the same
		if isinstance(p, dict):
			data = self.run_parameters(p)
		else:
			data = self.run_vector(p)

		if data is None:
			return -np.inf, utils.everythingIsNan

		# Otherwise we loop through the named likelihoods
		# and sum all the values we find for them
		like = self.extract_likelihood(data)
		if not self.quiet: print "Got like ", like

		extra_saves = {}
		for (section, name) in self.extra_saves:
			value = data.get_param(section, name, np.nan)
			code = '%s--%s' % (section,name)
			extra_saves['%s--%s'%(section,name)] = value
		extra_saves['LIKE'] = like

		if filename:
			data.save_to_file(filename)

		return like, extra_saves
